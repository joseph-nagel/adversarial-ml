{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from adv_utils import (\n",
    "    download_file,\n",
    "    FGSMAttack,\n",
    "    PGDAttack\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model weights\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "\n",
    "# create preprocessor\n",
    "preprocessor = weights.transforms()\n",
    "\n",
    "# load model\n",
    "model = resnet18(weights=weights)\n",
    "model = model.eval()\n",
    "\n",
    "# get class names\n",
    "class_names = weights.meta['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inverse normalization\n",
    "renormalizer = transforms.Compose([\n",
    "    # reverse normalization\n",
    "    transforms.Normalize(\n",
    "        mean=[-m/s for m, s in zip(preprocessor.mean, preprocessor.std)],\n",
    "        std=[1/s for s in preprocessor.std]\n",
    "    ),\n",
    "    # clip to valid range\n",
    "    transforms.Lambda(lambda x: x.clamp(0, 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image_path = '../test.jpg'\n",
    "\n",
    "if not Path(image_path).exists():\n",
    "    image_path = download_file(\n",
    "        url='https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg',\n",
    "        save_path=image_path\n",
    "    )\n",
    "\n",
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.imshow(np.asarray(image))\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess image\n",
    "x = preprocessor(image) # (3, h, w)\n",
    "x = x.unsqueeze(0) # (1, 3, h, w)\n",
    "\n",
    "# run model\n",
    "with torch.no_grad():\n",
    "    logits = model(x) # (1, 1000)\n",
    "\n",
    "# get predictions\n",
    "# label_ids = logits.argmax(dim=1) # (1,)\n",
    "probs = logits.softmax(dim=1) # (1, 1000)\n",
    "label_probs, label_ids = probs.max(dim=1) # (1,)\n",
    "labels = [class_names[lidx.item()] for lidx in label_ids]\n",
    "\n",
    "for l, p in zip(labels, label_probs):\n",
    "    print(f'Predicted: {l} ({p:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untargeted FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform FGSM attack\n",
    "fgsm = FGSMAttack(\n",
    "    model=model,\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    ")\n",
    "\n",
    "fgsm_x = fgsm(\n",
    "    image=x,\n",
    "    label=label_ids,\n",
    "    eps=0.005,\n",
    "    targeted=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "with torch.no_grad():\n",
    "    fgsm_logits = model(fgsm_x) # (1, 1000)\n",
    "\n",
    "# get predictions\n",
    "fgsm_probs = fgsm_logits.softmax(dim=1) # (1, 1000)\n",
    "fgsm_label_probs, fgsm_label_ids = fgsm_probs.max(dim=1) # (1,)\n",
    "fgsm_labels = [class_names[lidx.item()] for lidx in fgsm_label_ids]\n",
    "\n",
    "for l, p in zip(fgsm_labels, fgsm_label_probs):\n",
    "    print(f'Predicted: {l} ({p:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "plot_idx = 0\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax1.imshow(renormalizer(x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax1.set_title(f'Predicted: {labels[plot_idx]} ({label_probs[plot_idx]:.2f})')\n",
    "\n",
    "ax2.imshow(renormalizer(fgsm_x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax2.set_title(f'Predicted: {fgsm_labels[plot_idx]} ({fgsm_label_probs[plot_idx]:.2f})')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted PGD attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target label\n",
    "target_label = 1\n",
    "\n",
    "print(f'Target: {class_names[target_label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PGD attack\n",
    "pgd = PGDAttack(\n",
    "    model=model,\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    ")\n",
    "\n",
    "pgd_x = pgd(\n",
    "    image=x,\n",
    "    label=target_label,\n",
    "    num_steps=20,\n",
    "    step_size=0.1,\n",
    "    eps=5.,\n",
    "    p_norm=2,\n",
    "    targeted=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "with torch.no_grad():\n",
    "    pgd_logits = model(pgd_x) # (1, 1000)\n",
    "\n",
    "# get predictions\n",
    "pgd_probs = pgd_logits.softmax(dim=1) # (1, 1000)\n",
    "pgd_label_probs, pgd_label_ids = pgd_probs.max(dim=1) # (1,)\n",
    "pgd_labels = [class_names[lidx.item()] for lidx in pgd_label_ids]\n",
    "\n",
    "for l, p in zip(pgd_labels, pgd_label_probs):\n",
    "    print(f'Predicted: {l} ({p:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "plot_idx = 0\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax1.imshow(renormalizer(x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "ax1.set_title(f'Predicted: {labels[plot_idx]} ({label_probs[plot_idx]:.2f})')\n",
    "\n",
    "ax2.imshow(renormalizer(pgd_x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "ax2.set_title(f'Predicted: {pgd_labels[plot_idx]} ({pgd_label_probs[plot_idx]:.2f})')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
