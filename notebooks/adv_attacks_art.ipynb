{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial attacks (ART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import (\n",
    "    FastGradientMethod,\n",
    "    ProjectedGradientDescent\n",
    ")\n",
    "\n",
    "from adv_utils import download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model weights\n",
    "weights = ResNet101_Weights.DEFAULT\n",
    "\n",
    "# create preprocessor\n",
    "preprocessor = weights.transforms()\n",
    "\n",
    "# load model\n",
    "model = resnet101(weights=weights)\n",
    "model = model.eval()\n",
    "\n",
    "# get class names\n",
    "class_names = weights.meta['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessing function\n",
    "preprocess = lambda img: preprocessor(img).unsqueeze(0)\n",
    "\n",
    "# create inverse normalization\n",
    "mean = torch.as_tensor(preprocessor.mean).view(-1, 1, 1)\n",
    "std = torch.as_tensor(preprocessor.std).view(-1, 1, 1)\n",
    "\n",
    "renormalize = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x * std + mean), # reverse normalization\n",
    "    transforms.Lambda(lambda x: x.clamp(0, 1)) # clip to valid range\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ART model wrapper\n",
    "estimator = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    input_shape=(3, 224, 224),\n",
    "    nb_classes=len(class_names)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image_path = '../test.jpg'\n",
    "\n",
    "if not Path(image_path).exists():\n",
    "    _ = download_file(\n",
    "        url='https://upload.wikimedia.org/wikipedia/commons/4/48/Augustine_volcano_Jan_24_2006_-_Cyrus_Read.jpg',\n",
    "        save_path=image_path\n",
    "    )\n",
    "\n",
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.imshow(np.asarray(image))\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess image\n",
    "x = preprocess(image) # (1, 3, h, w)\n",
    "\n",
    "# run model\n",
    "with torch.no_grad():\n",
    "    logits = model(x) # (1, 1000)\n",
    "\n",
    "# get predictions\n",
    "# label_ids = logits.argmax(dim=1) # (1,)\n",
    "probs = logits.softmax(dim=1) # (1, 1000)\n",
    "label_probs, label_ids = probs.max(dim=1) # (1,)\n",
    "labels = [class_names[lidx.item()] for lidx in label_ids]\n",
    "\n",
    "for l, p in zip(labels, label_probs):\n",
    "    print(f'Predicted: {l} ({p:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untargeted FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform FGSM attack\n",
    "fgsm = FastGradientMethod(\n",
    "    estimator=estimator,\n",
    "    eps=0.005,\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "fgsm_x = fgsm.generate(x=x.numpy(), y=None)\n",
    "fgsm_x = torch.from_numpy(fgsm_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "with torch.no_grad():\n",
    "    fgsm_logits = model(fgsm_x) # (1, 1000)\n",
    "\n",
    "# get predictions\n",
    "fgsm_probs = fgsm_logits.softmax(dim=1) # (1, 1000)\n",
    "fgsm_label_probs, fgsm_label_ids = fgsm_probs.max(dim=1) # (1,)\n",
    "fgsm_labels = [class_names[lidx.item()] for lidx in fgsm_label_ids]\n",
    "\n",
    "for l, p in zip(fgsm_labels, fgsm_label_probs):\n",
    "    print(f'Predicted: {l} ({p:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "plot_idx = 0\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax1.imshow(renormalize(x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax1.set_title(f'Original: {labels[plot_idx]} ({label_probs[plot_idx]:.2f})')\n",
    "\n",
    "ax2.imshow(renormalize(fgsm_x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax2.set_title(f'Attacked: {fgsm_labels[plot_idx]} ({fgsm_label_probs[plot_idx]:.2f})')\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted PGD attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target label\n",
    "target_label = 1\n",
    "\n",
    "print(f'Target: {class_names[target_label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PGD attack\n",
    "pgd = ProjectedGradientDescent(\n",
    "    estimator=estimator,\n",
    "    norm=np.inf,\n",
    "    eps=0.02,\n",
    "    eps_step=0.001,\n",
    "    max_iter=70,\n",
    "    targeted=True\n",
    ")\n",
    "\n",
    "pgd_x = pgd.generate(x=x.numpy(), y=np.array([target_label]))\n",
    "pgd_x = torch.from_numpy(pgd_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "with torch.no_grad():\n",
    "    pgd_logits = model(pgd_x) # (1, 1000)\n",
    "\n",
    "# get predictions\n",
    "pgd_probs = pgd_logits.softmax(dim=1) # (1, 1000)\n",
    "pgd_label_probs, pgd_label_ids = pgd_probs.max(dim=1) # (1,)\n",
    "pgd_labels = [class_names[lidx.item()] for lidx in pgd_label_ids]\n",
    "\n",
    "for l, p in zip(pgd_labels, pgd_label_probs):\n",
    "    print(f'Predicted: {l} ({p:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "plot_idx = 0\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax1.imshow(renormalize(x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax1.set_title(f'Original: {labels[plot_idx]} ({label_probs[plot_idx]:.2f})')\n",
    "\n",
    "ax2.imshow(renormalize(pgd_x[plot_idx]).permute(1, 2, 0).numpy())\n",
    "ax2.set_title(f'Attacked: {pgd_labels[plot_idx]} ({pgd_label_probs[plot_idx]:.2f})')\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
